---
title: "Taking a stance: Working Without AI"
description: "My opinon on the state of AI in tech."
date: "2024-09-15"
tags: [
  "opinion"
]
---

<blockquote>
  The sad thing about artificial intelligence is that it lacks artifice and therefore intelligence.
  <cite>Jean Baudrillard</cite>
</blockquote>

I've decided to take a stance, though not a new or novel stance. I'm declining to interact with "artificial intelligence" beyond what is perhaps required for my day job or when it cannot be avoided. I will not seek it out or use it for any of my work, creatively or professionally.

The real question, dear reader, is why? Right now, I could argue that every big company and every app is packing some AI feature to stay relevant, and AI fatigue is real. It's hard to find any tech that doesn't have some large language model at play, but there are three main reasons for this decision, or rather, three things AI takes from us: time, knowledge, and energy.

## Double the work, double the pleasure
First up: time. Whenever I've attempted to leverage AI to make my life easier, I must double-check or validate the response. Given that LLMs return bespoke responses to our queries, we can never be sure that the response is valid; after all, AI does tend to hallucinate quite frequently. As such, it takes far more time to lean on AI for even the most simple tasks, such as writing Doc Blocks or helping define test coverage or other project requirements.

In the same amount of time spent thinking of how to phrase a question in such a way that it returns a helpful response, I could have spent either doing the work or researching a solution. In doing so, it brings me to the following reason: knowledge.

## Easy in easy out
The best parallel regarding knowledge retention is phone numbers. Pre-cell phone, I knew every number for all of my friends and family, as well as the local pizza spot off the top of my head. Once I got my first smartphone, I no longer needed to remember those numbers because my phone could handle that for me.

AI actively prevents us from learning new things. When we take the time to research and dig into concepts to form our own opinions, those ideas make their way into our long-term memories. The more we activate those muscles, the better off we will be as we age. AI doesn't allow us to learn because we only need to ask a question to get an answerâ€”regardless of how correct it might be.

One of the simple pleasures in life is learning new things, forming new opinions, and growing intellectually. I was actively losing brain cells (I'm being hyperbolic) while using AI Chatbots or AI features to try and improve my workflows. Other than taking my time and killing brain cells, we're headed toward a power and processing cap that I don't know we can come back from without a massive change in opinion.

## The ultimate trade-off
There is some exciting work in diagnostic medicine with AI, something I wish we'd devote more research to. Still, the most significant portion of AI research is done at the personal and business levels because of capitalism.

As a result, as more and more people and companies use AI chatbots and AI features built into our phones, and those LLMs become more and more complex, the resources required to sustain the exponential growth are staggering. Training one LLM can emit as much greenhouse gas as the entire lifetime of 5 vehicles <cite>[MIT Review](https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/)</cite>. Which in and of itself is enough for me to discontinue my use of AI and LLMs.

We're headed toward an energy crisis, creating a new industry of carbon emissions and impacting humans and wildlife alike during the displacement that occurs when building large data centers.
